# Rock, Paper, Scissors

이 대회는 두 에이전트가 가위바위보 천번을 겨뤄서 많이 이기는쪽이 이기는 대회이다.

핵심은 상대방의 패턴 파악이라고 할 수 있다.

Notebook을 참고해서 여러 간단한 모델을 살펴보았다. 개인적으로는 결정트리 방식이 생각보다 좋아서 놀랐는데 사실 왜 좋은지 모르겠다. 이 대회에서 '왜'라는 질문이 생각보다 어렵다는점이 좀 답답했다. 다른 대회에서는 복잡해서 모르겠는데 이 대회는 간단한데 모르겠는것이 근본적인 정보에 대한 이론을 생각해보게 되더라. 내 정보가 얼마나 새어나가고 있을까? 라는 생각이 계속해서 들었다.

또 A라는 에이전트를 완벽하게 카운터 치려면 어떤 전략을 써야 이길수 있을까? 라는것도 생각보다 쉽지 않았다. 일단 내쉬 평형을 압도하는건 불가능한것 같고(random number cracker같은 방법이 있긴 하더라) 위에 말한 결정트리를 이기는법은 안내던걸 내면 된다. 보통 상대방에 대한 계산을 하는 모델(결정트리같은)들이 일반적으로 성능이 높긴 하다. 

참가한지 며칠 안되었지만 현재까지 생각나는 해답은 내쉬 평형과는 비기고 나머지를 전부 이기는 에이전트를 만드는것이 가장 dominant한 에이전트가 아닌가 싶다.

그 외에 재미있는 이야기들은 가위바위보에 ELO 시스템이 적당한가에 대한 이야기들이 오가고 있더라. 그 외에 '매칭이 너무 운에 의존한다', '이전에 제출한 나쁜(오래된) 제출물때문에 noise가 너무 많다' 등등 대회 자체에 대한 토론도 재미있는 부분이 많았다. 아무래도 다른 대회보다는 운빨이라는게 존재하긴 하는 대회인것같다.

캐글 강화학습은 대부분 versus방식, 그러니까 제출물끼리 겨루는 방식이다. 1:1이나 1:1:1:1이나 일단 겨루고 결과 스코어에 따라서 ELO 시스템으로 점수를 결정내는듯 하다. 난 사실 이런 1:1 대결보다는 탐험을 하거나 어떤 액션을 배우는것을 더 많이 학습시켜봤고 그걸 더 좋아하기도 하는것같다.

사실 캐글 강화학습 대회를 나가본건 처음이라 조금 헤맸는데, 내부적으로 지켜야하는 경로가 있더라. '/kaggle_simulations/agent/' 경로에 실행중의 압축이 풀리는듯하다. 모델을 로드할때 이 경로로 열어주면 된다.  
그리고 매번 agent 함수가 호출되는 방식이라 데이터를 모으는 방식을 더 깔끔하게 할 순 없을까 생각이 든다. 매번 obs로 들어오는쪽을 구현하다보니 global로 데이터를 모으거나 하던데 썩... 좋진 않은것같다. 이 가위바위보 대회는 무언가를 분석하기 위해선 sequential한 feature를 실시간으로 만들어야만 하기 때문에 그런 구현이 필수적이다. env의 구현을 보니 웹과 파이썬 Pool이 섞여있던데 왜 이런방식을 사용하는지는 잘 모르겠다. 캐글 자체가 웹 기반이고 display/render를 하려면 웹에서 해야된다는건 알긴하겠는데... 뭐 다 이유가 있지 않을까 싶다. 이런 생각을 하는 이유는 생각보다 env가 상당히 느린거같아서... 빨랐으면 사실 별 생각 없었을것 같다.

뭐 아무튼 위에 말한대로 학습을 시켜서 로드시키는것까지 진행했다.


## 축구 대회하느라 : 20.12.01

축구 대회하느라 일주일동안 못했다. 그동안 랜덤 에이전트를 틈틈히 제출했는데 30등 정도에 머물러있다. 레전드.  
사실 이 대회는 생각할수록 모르겠어서... 진짜 모르겠다. 뭘 해야할지 감이 안온다.


## 최고점수 1070! : 2020.12.07

1074점까지 올라갔다가 현재 1등한테 지고 또져서 928점까지 내려왔다. 잠깐이나마 10위권 공기를 맡아보다니 감격스럽다고 해야할까...  
정말 운빨이 없을수가 없는 대회이긴 한데 상대방을 예측하는 에이전트가 아니면 상위권을 갈수가 없기도하다. 채점방식이 여러번 바뀐 이유가 있긴 있다. 내 고득점 랜덤 에이전트들은 다들 평균 점수로 천천히 떨어지고 있더라.

사실 내가 하고있는건 과거에 있었던 가위바위보 대회의 코드들을 참고해서 이러면 어떨까? 하면서 조금씩 바꿔서 제출하는정도이다. 1초를 충분히 다 사용하고 최대한 많은걸 예측해서 붙어보자는식이다. 그중 정말로 필요한건 위에서 말했듯이 하루에 5번씩 꼭 제출하는게 아닐까 싶다. 꾸준함이 중요한 대회라니 이걸 공정한거라고 봐야할지...


## 퍼피를 무찌르는방법 : 2020.12.12

centrifugal_bumblepuppy(노트북에 보면 있는 옛날 대회의 우승급의 모델)라는 모델이 있는데 이녀석이 꽤 robust하더라. 노트북에 공개되어있다는건 무슨뜻? 사람들이 많이 제출을 해본다는뜻이다. 그럼 이 퍼피를 무찌르는법을 익히면 꽤 괜찮을것이다. 그래서 퍼피를 잘 이기는 모델을 만들어서 제출했다.

문제는... 600->800구간이 의외로 헬이다. 운이 나쁘면 그냥 못올라간다. 여긴 말하자면 랜덤 에이전트들이 판치는 구간인데 재수없으면 그냥 랜덤만 주구장창 만나다가 못올라간다..

긍정적인 점은 현 2등(Stas SI)의 에이전트를 만날때마다 족족 깨졌는데 최신 모델 제출한건 비겼다. 과연 지속적으로 좋은 성능을 낼지 궁금하다.


## 돌파구 : 20.12.16

돌파구를 찾은것같다. 산타 대회를 하다가 산타 대회에 적용한걸 똑같이 가져왔는데 성능이 좋은것같더라. 이게 확률 게임에서 무언가 근본적으로 좋은 접근인건가? 잘 모르겠다...


## 정말 모르겠다 : 20.12.20

상위권들의 이야기를 들어보면 본인들도 운이 좋았다는것처럼 이야기한다(1등은 잘 모르겠다. 무언가 있긴 한듯). 더이상 어떤 방법을 시도해봐야할지 감이 안온다... 내가 무얼 하냐가 아니라 상대를 누구를 만나는지에 대한것은 내가 어쩔수가 있는게 아니다. 모든것을 알고있다면 제출 타이밍이라도 조절해보겠지만 당연히 모르기때문에 할 수 있는게 없다.

가장 어려운점은 가위바위보는 바보도 가끔은 이긴다는것이다. 아예 상성이 정해져있지 않은이상 아주 대단한 에이전트도 승률이 60, 70% 이렇게 넘어가지를 않는다. 그렇다보니 시간이 걸리거나 상성에 걸리거나 랜덤 에이전트에 걸리거나 별에 별 확률을 마주치게 되는데... 


## 정말 정말 모르겠다 : 20.12.27

위에서 말한 돌파구 이후에 아무 진전이 없었지만 그 모델을 계속 제출했고 그때 당시에는 죽을 쒔지만 지금은 15위다. 1037점. 아무래도 평가에 시간이 확실히 걸리는것 같다. 진짜 도저히 알수가 없다. 랜덤 구간을 뚫은 에이전트중에 강한 에이전트가 살아남는것일까... 

이거 쓰는 지금 1위를 이기고 12등 금메달 라인으로 들어왔다. 1053점. 글쎄... 정말 말도안되게 요동치는 점수라 잘 모르겠다.
