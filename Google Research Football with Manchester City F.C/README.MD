# Google Research Football with Manchester City F.C.

늦게 참가해서 시간이 없는것이 정말 아쉽다. 시도는 여러가지로 해봤는데 쉽지않다.  

일단 내가 생각해본것들을 정리해보자


## 대회에 대한 파악

일단 대회에 대해 파악해야했다. 첫 인상은 무진장 어려워보인다는 느낌이였는데 지금은 손쓸 방법을 모르겠다에 가까운것 같다. 

일단 대회가 어렵느냐. 꽤 어려운편에 속한다. 강화학습은 총 에피소드 길이는 긴데(여기선 3000) 그 안에서 짧은구간에 훌륭한 컨트롤을 수행해야 하는 상황에서 학습량이 부족하면 잘 학습하지 못한다. 이건 당연하기도 하고 그냥 어려운것이다. 사람도 마찬가지로 골키퍼를 마주쳤을 때 A-B-C의 시퀀스를 적절하게 입력해서 골을 넣는것은 숙련된 게이머나 할 수 있는것이다.

일단 남은 시간은 별로 없고 캐글에서 제공하는 컴퓨팅 파워의 성능이 압도적으로 좋은것도 아니며 환경의 SPS도 빠르지않다. 쉽게 말하면 '강화학습 하기 좋은 환경이 아니다'라는 것이다. 그럼 어떻게 하는게 좋을까?


## 대회 끝나가는 상황에서 다른 노트북들 살펴보기

일단 메모리 패턴이라고 공개되어있는걸 살펴봤다. 여기서 살펴보면서 느낀건데, offence에 비해 defence 행동이 굉장히 빈약하더라. 그 이유가 뭔가 하니 일반적으로 축구는 수비들의 유기적인 움직임이 중요한데 그건 내가 컨트롤하는것도 아니고 그냥 게임 환경이 알아서 한다. 그러니까 내가 할 수 있는게 별로 없다는것이다. 내가 축구 감독처럼 '상대방이 공격할때 이런 진형으로 방어해라~' 라고 전체적인 명령을 내릴 수 있는게 아니다.  

물론 답은 있긴 할것이다. 상대방이 드리블할때 스프린트를 하면서 공에 플레이어가 다가가고 게임 내에 구현되어있는 어떤 규칙에 따라서 공을 뺏을 수 있을것이다(내가 알기론 공을 뺏은 직후에는 뺏을 수 없고 이런식으로 구현되어있는걸로 알고있다.). 이런 태클의 경우에도 (일반적으로 스프린트의 속도는 x이기 때문에 공의 그 속도는 y이므로 시간차를 고려하여 z 위치로 태클을 건다) 등의 완벽한 계산이 있으면 할 수는 있다. 하지만 그 규칙을 알아내기란 어려운 일이다. 그러니까 보통은 할 수 있는게 공을 향해 달린다는게 거의 유일한 선택지가 된다.

이걸 다시말하면 수비는 어렵고(선택의 여지가 별로 없고) 공격은 쉽다(스스로 무언가 만들어낼 수 있는 가능성이 높다)라고도 볼 수 있다. 공격은 골이 잘 들어가는 골키퍼와의 거리를 유지한 채 정확한 각도에서 사이드로 약간 무빙한뒤에 슛을 쏘는 정확한 메카닉 등이 있다면 수월하게 골을 넣을 수 있다.  


## rule base가 더 좋을까?

한정된 학습자원이라면 룰베이스가 어쩔 수 없이 강화학습보단 강할 수 밖에 없다. 아마도 잘은 모르겠지만 이 환경이 어떻게 되어있는지 잘 해킹하는쪽이 난 더 성능이 높을거같다. 학습으로 따라잡기엔 여러모로 어려운점이 많아보인다. 아마 상위권들도 룰베이스가 꽤 많을것같다. 정확히는 모르겠지만 플레이를 지켜보면 룰베이스 같다는 생각이 들긴한다.

그리고 룰베이스를 강하게 만들어주는것 중 하나가 'ball_owned_team'이라는 명확한 지표가 이 상황에서 무슨 행동을 해야할지를 나타내준다. 조건문으로 볼을 가지고 있지 않을때에는 방어를, 볼을 가지고 있을때에는 공격을 하면 된다. 반면 딥러닝 에이전트는 좀 더 학습할게 늘어날뿐이다. 어떻게해야 공수를 깔끔하게 번갈아가면서 학습할 수 있을까 고민해봤지만 좀처럼 쉽지 않았다.


## 공격에 집중

기가막힌 수비 방법이 있을 수 있다. 하지만 나는 아무리 생각해봐도 수비를 잘하는법은 모르겠더라. 그래서 수비에 대한 액션은 전부 포기했다. 내가 공을 가지고 있지 않을때에는 공을 향해 달리는 액션 뿐이다.

공격에 집중하겠다고 했지만 공격을 학습시키는것도 어려운 일인데 골키퍼를 파훼하는것이 간단하지 않기 때문이다. 사람은 대략적으로 (골키퍼와 일직선이 아닌 상태 -> 슛을 쏨) 이라던가 (각도가 좋지 않음 -> 센터쪽으로 패스함 -> 슛을 쏨) 이라던가의 일반적인 더 좋은 슈팅에 대한 개념을 알고있지만 에이전트에게 그런걸 기대하기는 어려운일이다. 그래서 공격은 


## reward function 추가

dense한 reward fuction을 두가지 추가했는데, 하나는 볼 점유율이고 하나는 공의 위치에 대한 reward이다. 볼을 더 많이 가지고 있을수록, 공이 상대방 진영에 더 오래 있을수록 리워드를 받도록 했다. 이런식으로 최적성과 효율 사이의 trade off를 주는것은 당장의 상황에서 어쩔 수 없이 필요하다고 본다. 중간중간 이상한 방향으로 학습되기도 하기 때문에 참 까다로운 문제이다. 학습의 중간다리 역할을 할 때가 정말 많기때문에 필요하다고 생각되어 넣었다.


## 좋은 액션의 선택


